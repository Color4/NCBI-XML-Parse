{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筛选待下载新文献，手动下周 XML格式文件\n",
    "- https://www.ncbi.nlm.nih.gov/labs/pmc/\n",
    "- ((spatial[All Fields] AND \"tissue sections\"[All Fields]) OR \"spatially resolved transcriptomic\"[All Fields] OR \"spatial expression pattern\"[All Fields] OR \"spatial transcriptomic\"[All Fields] OR \"spatial gene expression\"[All Fields] OR \"spatial omics\"[All Fields] OR \"spatial profile\"[All Fields] OR \"spatial profiling\"[All Fields]) AND (\"2021/07/01\"[PubDate] : \"3000\"[PubDate])\n",
    "- \"High-Resolution Transcriptomic\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_columns\",None)\n",
    "import tarfile\n",
    "import requests\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# coding = utf-8\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "d = date.today()\n",
    "year=str(d.year)\n",
    "month=str(d.month)\n",
    "day= str(d.day)\n",
    "if len(month)==1:\n",
    "    month=\"0\"+month\n",
    "if len(day)==1:\n",
    "    day=\"0\"+day\n",
    "Taday_date=year+\"-\"+month+\"-\"+day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_article_meta(soup,pmc_file):\n",
    "    Ids =[]\n",
    "    paper_type =\"\"\n",
    "    title =\"\"\n",
    "    Authors =[]\n",
    "    Author_Infor =[]\n",
    "    PubDate =[]\n",
    "    Abstract =[]\n",
    "    Keywords =[]\n",
    "    jour_Ids =[]\n",
    "    article_meta = soup.find_all(\"article-meta\")\n",
    "    for meta in article_meta:\n",
    "        # 获取 文章相关的 ID\n",
    "        IDS = meta.find_all(\"article-id\")\n",
    "        for ID in IDS:\n",
    "            Ids.append(ID[\"pub-id-type\"]+\":\"+ID.text)\n",
    "        try:\n",
    "            paper_type = meta.find(\"article-categories\").text.strip()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            title = meta.find(\"article-title\").text.strip()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "        # 作者和作者信息\n",
    "        authors = meta.find_all(\"contrib\")\n",
    "        for author in authors:\n",
    "            try:\n",
    "                author_name = author.find(\"given-names\").text.strip()+\" \"+author.find(\"surname\").text.strip()\n",
    "                try:\n",
    "                    author_xref = author.find(\"xref\")[\"ref-type\"]+\"-\"+author.find(\"xref\")[\"rid\"]\n",
    "                    Authors.append(author_xref+\":\"+author_name)\n",
    "                except:\n",
    "                    Authors.append(author_name)\n",
    "            except:\n",
    "                author_name = author.text.strip()\n",
    "                Authors.append(author_name)\n",
    "            \n",
    "            \n",
    "        author_infor =meta.find_all(\"aff\")\n",
    "        for infor in author_infor:\n",
    "            try:\n",
    "                aff = \"aff-\"+infor[\"id\"]+\":\"+infor.text.strip()\n",
    "                Author_Infor.append(aff)\n",
    "            except Exception as e:\n",
    "                #print(e)\n",
    "                aff = infor.text.strip()\n",
    "                Author_Infor.append(aff)\n",
    "        \n",
    "        # 发表时间\n",
    "        pub_date =meta.find_all(\"pub-date\")\n",
    "        for  dates in pub_date:\n",
    "            try:\n",
    "                year = dates.find(\"year\").text.strip()\n",
    "            except:\n",
    "                year =\"\"\n",
    "            try:\n",
    "                month = dates.find(\"month\").text.strip()\n",
    "            except:\n",
    "                month =\"\"\n",
    "            try:\n",
    "                day = dates.find(\"day\").text.strip()\n",
    "            except:\n",
    "                day =\"\"\n",
    "            try:\n",
    "                PubDate.append(dates[\"pub-type\"]+\":\"+\"-\".join([year,month,day]))\n",
    "            except:\n",
    "                PubDate.append(\"-\".join([year,month,day]))\n",
    "            \n",
    "        # 摘要\n",
    "        abstract = meta.find_all(\"abstract\")\n",
    "        paras =[]\n",
    "        for ab in abstract:\n",
    "            paras +=ab.find_all(\"p\")\n",
    "            for p in paras:\n",
    "                Abstract.append(p.text)\n",
    "                \n",
    "        # 关键词\n",
    "        keywords = meta.find_all(\"kwd\")\n",
    "        for kwd in keywords:\n",
    "            Keywords.append(kwd.text.strip())\n",
    "            \n",
    "        #解析杂志相关信息\n",
    "        journal_meta = soup.find_all(\"journal-meta\")\n",
    "        journal_title=\"\"\n",
    "        for meta in journal_meta:\n",
    "            IDS = meta.find_all(\"journal-id\")\n",
    "            for ID in IDS:\n",
    "                jour_Ids.append(ID[\"journal-id-type\"]+\":\"+ID.text)\n",
    "            journal_title = meta.find(\"journal-title\").text.strip() \n",
    "            ISSNs = meta.find_all(\"issn\")\n",
    "            issn_Number=[]\n",
    "            for issn in ISSNs:\n",
    "                issn_Number.append(issn.text.strip())\n",
    "            issn_Number=\"; \".join(issn_Number)\n",
    "    try:\n",
    "        return \"; \".join(Ids),paper_type,title,\"; \".join(Authors),\"; \".join(Author_Infor),\"; \".join(PubDate),\"\\n\".join(Abstract),\"; \".join(Keywords),\"; \".join(jour_Ids),journal_title,issn_Number\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"; \".join(Ids),paper_type,title,\"; \".join(Authors),\"; \".join(Author_Infor),\"; \".join(PubDate),\"\\n\".join(Abstract),\"; \".join(Keywords),\"; \".join(jour_Ids),\".\",issn_Number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析正文部分\n",
    "def parse_body(body,pmc_file,Work_Path):\n",
    "    body_id =[]\n",
    "    body_title =[]\n",
    "    body_content =[]\n",
    "    Sections = body.find_all(\"sec\")\n",
    "    for sec in Sections:\n",
    "        try:\n",
    "            body_id.append(sec[\"id\"])\n",
    "        except:\n",
    "            body_id.append(\"\")\n",
    "                \n",
    "        try:\n",
    "            body_title.append(sec.find(\"title\").text.strip())\n",
    "        except:\n",
    "            body_title.append(\"\")\n",
    "            \n",
    "        try:\n",
    "            paras =[]\n",
    "            conts = sec.find_all(\"p\")\n",
    "            for c in conts:\n",
    "                paras.append(c.text.strip())\n",
    "            body_content.append(\"\\n\".join(paras))\n",
    "        except:\n",
    "            body_content.append(\"\")\n",
    "                \n",
    "    df = pd.DataFrame(body_title,columns=[\"Title\"])\n",
    "    try:\n",
    "        df[\"Text_Id\"]= pd.DataFrame(body_id)\n",
    "    except:\n",
    "        df[\"Text_Id\"]=\"\"\n",
    "    try:\n",
    "        df[\"Content\"]= pd.DataFrame(body_content)\n",
    "    except:\n",
    "        df[\"Content\"]=\"\"\n",
    "    df[\"PMCID\"]= pmc_file\n",
    "    df=df[[\"PMCID\",\"Title\",\"Text_Id\",\"Content\"]]\n",
    "    if df.shape[0]>0:\n",
    "        df.to_excel(\"..\\\\ResultPMC\\\\\"+pmc_file+\"\\\\\"+pmc_file+\"_paragraphs.xlsx\",index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析图片 标题，label, html\n",
    "import urllib.request\n",
    "def parse_figure(soup,pmc_file,Work_Path):\n",
    "    figs =soup.findAll(\"fig\")\n",
    "    Label =[]\n",
    "    Title =[]\n",
    "    HTML =[]\n",
    "    Full_URL=[]\n",
    "    for fig in figs:\n",
    "        # 解析 标签 和 表格标题\n",
    "        label=\"\"\n",
    "        title =\"\"\n",
    "        try:\n",
    "            label =fig.findAll(\"label\")[0].text.strip()\n",
    "        except:\n",
    "            label =\"Figure \"+str(figs.index(fig)+1)\n",
    "        #print(\"Label\",label)\n",
    "        try:\n",
    "            title =fig.text.strip().replace(label,\"\").strip(\"\\n\")\n",
    "        except:\n",
    "            pass\n",
    "        #print(title)\n",
    "        try:\n",
    "            url =fig.find(\"graphic\")[\"xlink:href\"]\n",
    "            full_url = \"https://www.ncbi.nlm.nih.gov/pmc/articles/\"+pmc_file+\"/bin/\"+url+\".jpg\"\n",
    "        except:\n",
    "            url =\"\"\n",
    "            full_url = \"\"\n",
    "        Label.append(label)\n",
    "        Title.append(title)\n",
    "        HTML.append(url)\n",
    "        Full_URL.append(full_url)\n",
    "    if len(Label)>0:\n",
    "        df_infor = pd.DataFrame(Label,columns=[\"Label\"])\n",
    "        df_infor[\"Caption\"]= pd.DataFrame(Title)\n",
    "        df_infor[\"Name\"]= pd.DataFrame(HTML)\n",
    "        df_infor[\"PMCID\"]=pmc_file\n",
    "        df_infor[\"Full_URL\"]=pd.DataFrame(Full_URL)\n",
    "        df_infor = df_infor[[\"PMCID\",\"Label\",\"Caption\",\"Name\",\"Full_URL\"]]\n",
    "        df_infor.to_excel(\"..\\\\ResultPMC\\\\\"+pmc_file+\"\\\\\"+pmc_file+\"_figures.xlsx\",index=False)\n",
    "        return df_infor\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析表格内容\n",
    "def parse_table(soup,pmc_file,Work_Path):\n",
    "    tbs =soup.findAll(\"table-wrap\")\n",
    "    Label =[]\n",
    "    Title =[]\n",
    "    for tb in tbs:\n",
    "        # 解析 标签 和 表格标题\n",
    "        label=\"\"\n",
    "        title =\"\"\n",
    "        try:\n",
    "            label =tb.findAll(\"label\")[0].text.strip()\n",
    "        except:\n",
    "            label =\"Table \"+str(tbs.index(tb)+1)\n",
    "        #print(\"Label\",label)\n",
    "        try:\n",
    "            paras =tb.findAll(\"p\")\n",
    "            for p in paras:\n",
    "                title += p.text.strip()+\". \"\n",
    "        except:\n",
    "            pass\n",
    "        #print(title)\n",
    "        \n",
    "        # 解析 表格内容\n",
    "        th = tb.findAll(\"th\")\n",
    "        cols = [i.text.strip() for i in th]\n",
    "        for col in cols:\n",
    "            if col==\"\":\n",
    "                cols.remove(col)\n",
    "        #print(\"Headers:\",cols)\n",
    "        trs=tb.findAll(\"tr\")\n",
    "        values=[]\n",
    "        for tr in trs[1:]:\n",
    "            values.append([i.text for i in tr.findAll(\"td\")])\n",
    "        for i in range(len(values)):\n",
    "            if len(values[i])<len(cols):\n",
    "                values[i]=[\"-\"]*(len(cols)-len(values[i]))+values[i]\n",
    "        #print(trs)\n",
    "        max_col =0\n",
    "        for i in values:\n",
    "            if len(i)>max_col:\n",
    "                max_col =len(i)\n",
    "        if values !=[]:\n",
    "            if len(cols)<max_col:\n",
    "                df_t = pd.DataFrame(values)\n",
    "            else:\n",
    "                df_t = pd.DataFrame(values,columns=cols)\n",
    "            df_t[\"Label\"]=\"\"\n",
    "            df_t.loc[0,\"Label\"]=label\n",
    "            df_t[\"Title\"]=\"\"\n",
    "            df_t.loc[0,\"Title\"]=title\n",
    "            try:\n",
    "                df_t.to_excel(\"..\\\\ResultPMC\\\\\"+pmc_file+\"\\\\\"+pmc_file+\"_tables\"+\"_\"+str(label)+\".xlsx\",index=False)\n",
    "            \n",
    "            except:\n",
    "                df_t.to_excel(\"..\\\\ResultPMC\\\\\"+pmc_file+\"\\\\\"+pmc_file+\"_tables\"+\"_\"+str(tbs.index(tb)+1)+\".xlsx\",index=False)\n",
    "                \n",
    "           \n",
    "            Label.append(label)\n",
    "            Title.append(title)\n",
    "    if len(Label)>0:\n",
    "        df_infor = pd.DataFrame(Label,columns=[\"Label\"])\n",
    "        df_infor[\"Caption\"]= pd.DataFrame(Title)\n",
    "        df_infor[\"PMCID\"]=pmc_file\n",
    "        return df_infor\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析参考文献\n",
    "def parse_ref_list(soup,pmc_file,Work_Path):\n",
    "    Ref_list = soup.find_all(\"ref-list\")\n",
    "    Ref_ID=[]\n",
    "    Ref_label =[]\n",
    "    Ref_citation =[]\n",
    "    Authors =[]\n",
    "    Title =[]\n",
    "    PubID =[]\n",
    "    for data in Ref_list:\n",
    "        refs = data.find_all(\"ref\")\n",
    "        for ref in refs:\n",
    "            ref_id=\"\"\n",
    "            try:\n",
    "                ref_id=ref[\"id\"].strip()\n",
    "            except:\n",
    "                ref_id=refs.index(ref)+1\n",
    "            authors =[]\n",
    "            try:\n",
    "                Ref_label.append(ref.find(\"label\").text.strip())\n",
    "            except:\n",
    "                Ref_label.append(\"\")\n",
    "                \n",
    "            try:\n",
    "                names =ref.find_all(\"name\")\n",
    "                #print(names)\n",
    "                for name in names:\n",
    "                    #print(name.find(\"given-names\").text.strip())\n",
    "                    authors.append(name.find(\"surname\").text.strip()+' '+name.find(\"given-names\").text.strip())\n",
    "                \n",
    "                title = ref.find(\"article-title\").text.strip()\n",
    "                try:\n",
    "                    source = ref.find(\"source\").text.strip()\n",
    "                except:\n",
    "                    source=\"\"\n",
    "                try:\n",
    "                    year =ref.find(\"year\").text.strip()\n",
    "                except:\n",
    "                    year =\"\"\n",
    "                try:\n",
    "                    volume = ref.find(\"volume\").text.strip()\n",
    "                except:\n",
    "                    volume=\"\"\n",
    "                try:\n",
    "                    issue = ref.find(\"issue\").text.strip()\n",
    "                    fpage = ref.find(\"fpage\").text.strip()\n",
    "                    lpage = ref.find(\"lpage\").text.strip()\n",
    "                except:\n",
    "                    issue =\"\"\n",
    "                    fpage =\"\"\n",
    "                    lpage=\"\"\n",
    "                try:\n",
    "                    pub_id = \"\"\n",
    "                    for p in ref.findAll(\"pub-id\"):\n",
    "                        pub_id+=p[\"pub-id-type\"]+\" : \"+p.text.strip()+\"; \"\n",
    "                except:\n",
    "                    pub_id =''\n",
    "                    pub_id_type =\"\"\n",
    "            \n",
    "                if pub_id !=\"\":\n",
    "                    Ref_citation.append(\", \".join(authors)+\". \"+title+\". \"+source+\". \"+year+\";\"+volume+\"(\"+issue+\"):\"+fpage+\"-\"+lpage+\".\"+pub_id)\n",
    "                else:\n",
    "                    Ref_citation.append(\", \".join(authors)+\". \"+title+\". \"+source+\". \"+year+\";\"+volume+\"(\"+issue+\"):\"+fpage+\"-\"+lpage+\".\")\n",
    "                Authors.append('; '.join(authors))\n",
    "                Title.append(title)\n",
    "                PubID.append(pub_id)\n",
    "                Ref_ID.append(ref_id)\n",
    "                \n",
    "            except:\n",
    "                Ref_citation.append(\"\")\n",
    "                Authors.append(\"\")\n",
    "                Title.append(\"\")\n",
    "                PubID.append(\"\")\n",
    "                Ref_ID.append(ref_id)\n",
    "            \n",
    "    \n",
    "    if len(Ref_citation)>0:\n",
    "        df = pd.DataFrame(Ref_label,columns=[\"Ref_label\"])\n",
    "        df[\"Ref_ID\"]= pd.DataFrame(Ref_ID)\n",
    "        df[\"Ref_citation\"]= pd.DataFrame(Ref_citation)\n",
    "        df[\"Authors\"]= pd.DataFrame(Authors)\n",
    "        df[\"Ref_PubID\"] = pd.DataFrame(PubID)\n",
    "        df[\"Title\"] = pd.DataFrame(Title)\n",
    "        df[\"PMCID\"]= pmc_file\n",
    "        df = df[[\"PMCID\",\"Ref_ID\",\"Ref_PubID\",\"Title\",\"Authors\",\"Ref_citation\"]]\n",
    "        df.to_excel(\"..\\\\ResultPMC\\\\\"+\"\\\\\"+pmc_file+\"\\\\\"+pmc_file+\"_References.xlsx\",index=False)\n",
    "        return df\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_data(PMC_file,Taday_date):\n",
    "    Work_Path =\"E:\\\\PMC\\\\\"+PMC_file+\"\\\\\"\n",
    "    PMC =[]\n",
    "    IDs =[]\n",
    "    Paper_Type =[]\n",
    "    Title =[]\n",
    "    Authors =[]\n",
    "    Author_Infor =[]\n",
    "    PubDate =[]\n",
    "    Abstract =[]\n",
    "    Keywords =[]\n",
    "    Journal_Ids=[]\n",
    "    Journal_Title =[]\n",
    "    Journal_ISSN=[]\n",
    "    count =0\n",
    "    files= os.listdir(Work_Path)\n",
    "    \n",
    "    for file in files:\n",
    "        if \".xml\" in file:\n",
    "\n",
    "            # 读取 xml格式文件内容\n",
    "            PMC_xml =Work_Path+\"\\\\\"+file\n",
    "            try:\n",
    "                with open(PMC_xml,encoding=\"utf-8\") as f:\n",
    "                    lines = \" \".join(f.readlines())\n",
    "                    f.close()\n",
    "            except:\n",
    "                    lines=[]\n",
    "\n",
    "            if lines !=[]:# 解析文件内容\n",
    "                BS = BeautifulSoup(lines,\"lxml\")\n",
    "                article_list = BS.find_all(\"article\")\n",
    "                for body in article_list:\n",
    "                    pmc_file=body.find(\"article-meta\").find(\"article_id\",_type=\"pmid\")\n",
    "                    para_df=parse_body(body,pmc_file,Work_Path)\n",
    "                    fig_df=parse_figure(body,pmc_file,Work_Path)\n",
    "                    tb_df=parse_table(body,pmc_file,Work_Path)\n",
    "                    ref_df=parse_ref_list(body,pmc_file,Work_Path)\n",
    "                    article_meta = body.find_all(\"article-meta\")\n",
    "                    if article_meta !=[]:\n",
    "                        # 1）解析 文章信息\n",
    "                        Ids,paper_type,title,authors,author_infor,pubdate,abstract,keywords,jour_Ids,journal_title,issn_number = parse_article_meta(soup,pmc_file)\n",
    "\n",
    "                        # 将信息存入列表\n",
    "                        PMC.append(pmc_file)\n",
    "                        IDs.append(Ids)\n",
    "                        Paper_Type.append(paper_type)\n",
    "                        Title.append(title)\n",
    "                        Authors.append(authors)\n",
    "                        Author_Infor.append(author_infor)\n",
    "                        PubDate.append(pubdate)\n",
    "                        Abstract.append(abstract)\n",
    "                        Keywords.append(keywords)\n",
    "                        Journal_Ids.append(jour_Ids)\n",
    "                        Journal_Title.append(journal_title)\n",
    "                        Journal_ISSN.append(issn_number)\n",
    "    Paper_Infor = pd.DataFrame(PMC,columns=[\"PMCID\"])\n",
    "    Paper_Infor[\"IDs\"] = pd.DataFrame(IDs)\n",
    "    Paper_Infor[\"Paper_Type\"] = pd.DataFrame(Paper_Type)\n",
    "    Paper_Infor[\"Title\"] = pd.DataFrame(Title)\n",
    "    Paper_Infor[\"Authors\"] = pd.DataFrame(Authors)\n",
    "    Paper_Infor[\"Author_Infor\"] = pd.DataFrame(Author_Infor)\n",
    "    Paper_Infor[\"PubDate\"] = pd.DataFrame(PubDate)\n",
    "    Paper_Infor[\"Abstract\"] = pd.DataFrame(Abstract)\n",
    "    Paper_Infor[\"Keywords\"] = pd.DataFrame(Keywords)\n",
    "    Paper_Infor[\"Journal_Ids\"] = pd.DataFrame(Journal_Ids)\n",
    "    Paper_Infor[\"Journal_Title\"] = pd.DataFrame(Journal_Title)\n",
    "    Paper_Infor[\"IF\"]=Paper_Infor[\"Journal_Title\"].apply(lambda x:IF_dic[str(x).upper()] if str(x).upper() in IF_dic else -1)\n",
    "    print(\"解析文章数目：\",Paper_Infor.shape)            \n",
    "    Paper_Infor.to_excel(\"../Result/\"+Taday_date+\"_\"+PMC_file+\"_PMC_Articals_Paper_Infor.xlsx\",index=False)\n",
    "    return Paper_Infor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Round=0\n",
    "PMC_file=\"../test_sample/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmc_result.xml\n",
      "131\n",
      "解析文章数目： (131, 12)\n"
     ]
    }
   ],
   "source": [
    "Work_Path =PMC_file # 检索下载的 XML文件路径\n",
    "PMC =[]\n",
    "IDs =[]\n",
    "Paper_Type =[]\n",
    "Title =[]\n",
    "Authors =[]\n",
    "Author_Infor =[]\n",
    "PubDate =[]\n",
    "Abstract =[]\n",
    "Keywords =[]\n",
    "Journal_Ids=[]\n",
    "Journal_Title =[]\n",
    "Journal_ISSN=[]\n",
    "count =0\n",
    "\n",
    "files= os.listdir(Work_Path)\n",
    "for file in files:\n",
    "    if file.endswith(\".xml\") and file.startswith(\"pmc\"):\n",
    "        print(file)\n",
    "        # 读取 xml格式文件内容\n",
    "        PMC_xml =Work_Path+\"\\\\\"+file\n",
    "        try:\n",
    "            with open(PMC_xml,encoding=\"utf-8\") as f:\n",
    "                lines = \" \".join(f.readlines())\n",
    "                f.close()\n",
    "        except:\n",
    "            lines=[]\n",
    "\n",
    "        if lines !=[]:# 解析文件内容\n",
    "            BS = BeautifulSoup(lines,\"lxml\")\n",
    "            article_list = BS.find_all(\"article\")\n",
    "            print(len(article_list))\n",
    "            for article in article_list: \n",
    "                article_meta = article.find_all(\"article-meta\")#\n",
    "                pmcid=\"\"\n",
    "                pmid=\"\"\n",
    "                doi=\"\"\n",
    "                if article_meta !=[]:\n",
    "                    # 1）解析 文章信息\n",
    "                    article_ids=article_meta[0].find_all(\"article-id\")\n",
    "                    for art_id in article_ids:\n",
    "                        if art_id[\"pub-id-type\"]==\"pmc\":\n",
    "                            pmcid=\"PMC\"+art_id.text.strip()\n",
    "                        elif art_id[\"pub-id-type\"]==\"pmid\":\n",
    "                            pmid=\"PMID: \"+art_id.text.strip()\n",
    "                        elif art_id[\"pub-id-type\"]==\"doi\":\n",
    "                            doi=\"DOI: \"+art_id.text.strip()\n",
    "                    \n",
    "                    if pmcid not in os.listdir(Work_Path):\n",
    "                        os.mkdir(Work_Path+\"\\\\\"+pmcid)\n",
    "                    para_df=parse_body(article,pmcid,Work_Path)\n",
    "                    fig_df=parse_figure(article,pmcid,Work_Path)\n",
    "                    tb_df=parse_table(article,pmcid,Work_Path)\n",
    "                    ref_df=parse_ref_list(article,pmcid,Work_Path)\n",
    "                    Ids,paper_type,title,authors,author_infor,pubdate,abstract,keywords,jour_Ids,journal_title,issn_number = parse_article_meta(article,pmcid)\n",
    "\n",
    "                    # 将信息存入列表\n",
    "                    PMC.append(pmcid)\n",
    "                    IDs.append(Ids)\n",
    "                    Paper_Type.append(paper_type)\n",
    "                    Title.append(title)\n",
    "                    Authors.append(authors)\n",
    "                    Author_Infor.append(author_infor)\n",
    "                    PubDate.append(pubdate)\n",
    "                    Abstract.append(abstract)\n",
    "                    Keywords.append(keywords)\n",
    "                    Journal_Ids.append(jour_Ids)\n",
    "                    Journal_Title.append(journal_title)\n",
    "                    Journal_ISSN.append(issn_number)\n",
    "        \n",
    "Paper_Infor = pd.DataFrame(PMC,columns=[\"PMCID\"])\n",
    "Paper_Infor[\"IDs\"] = pd.DataFrame(IDs)\n",
    "Paper_Infor[\"Paper_Type\"] = pd.DataFrame(Paper_Type)\n",
    "Paper_Infor[\"Title\"] = pd.DataFrame(Title)\n",
    "Paper_Infor[\"Authors\"] = pd.DataFrame(Authors)\n",
    "Paper_Infor[\"Author_Infor\"] = pd.DataFrame(Author_Infor)\n",
    "Paper_Infor[\"PubDate\"] = pd.DataFrame(PubDate)\n",
    "Paper_Infor[\"Abstract\"] = pd.DataFrame(Abstract)\n",
    "Paper_Infor[\"Keywords\"] = pd.DataFrame(Keywords)\n",
    "Paper_Infor[\"Journal_Ids\"] = pd.DataFrame(Journal_Ids)\n",
    "Paper_Infor[\"Journal_Title\"] = pd.DataFrame(Journal_Title)\n",
    "Paper_Infor[\"ISSN\"] = pd.DataFrame(Journal_ISSN)\n",
    "#Paper_Infor[\"IF\"]=Paper_Infor[\"Journal_Title\"].apply(lambda x:IF_dic[str(x).upper()] if str(x).upper() in IF_dic else -1)\n",
    "print(\"解析文章数目：\",Paper_Infor.shape)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pmid(ids):\n",
    "    ids = ids.split(\"; \")\n",
    "    for i in ids:\n",
    "        if i.startswith(\"pmid:\"):\n",
    "            return i.split(\":\")[1]\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paper_Infor[\"PMID\"]=Paper_Infor[\"IDs\"].apply(get_pmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Round+=1\n",
    "Paper_Infor.to_excel(\"../Result/\"+Taday_date+\"_PMC_Articals_Paper_Infor.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
